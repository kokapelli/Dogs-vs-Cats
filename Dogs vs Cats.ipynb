{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 2\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "TRAIN_DIR = 'C:/Users/Kukus/Desktop/Kaggle/Dogs vs Cats/train/'\n",
    "TEST_DIR = 'C:/Users/Kukus/Desktop/Kaggle/Dogs vs Cats/test/'\n",
    "IMG_SIZE = 150\n",
    "TOTAL_PIXELS = IMG_SIZE * IMG_SIZE\n",
    "train_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)]\n",
    "test_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    label = img.split('.')[-3]\n",
    "    if label == 'cat': return 1\n",
    "    elif label == 'dog': return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_train_data():\n",
    "#    training_data = list()\n",
    "#    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "#        label = label_img(img)\n",
    "#        path = os.path.join(TRAIN_DIR, img)\n",
    "#        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "#        training_data.append([np.array(img), np.array(label)])\n",
    "#    shuffle(training_data)\n",
    "#    np.save('train_data.npy', training_data)\n",
    "#    return training_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays: \n",
    "        x is an array of resized images\n",
    "        y is an array of labels\n",
    "    \"\"\"\n",
    "    x = [] # images as arrays\n",
    "    y = [] # labels\n",
    "    \n",
    "    for image in tqdm(list_of_images):\n",
    "        img = cv2.resize(cv2.imread(image), (IMG_SIZE,IMG_SIZE), interpolation=cv2.INTER_CUBIC)\n",
    "        x.append(img)\n",
    "    \n",
    "    for i in list_of_images:\n",
    "        if 'dog' in i:\n",
    "            y.append(1)\n",
    "        elif 'cat' in i:\n",
    "            y.append(0)\n",
    "        #else:\n",
    "            #print('neither cat nor dog name present in images')\n",
    "            \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = list()\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR, img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:38<00:00, 254.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_data = prepare_data()\n",
    "X, Y = prepare_data(train_images_dogs_cats)\n",
    "#train_data = create_train_data()\n",
    "# if you already have train data:\n",
    "# train_data ? np.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(idx):\n",
    "    img = read_image(train_data[idx])\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider Normalizing the data\n",
    "#train_data = np.array(train_data)\n",
    "#tt = train_data[0][0] / train_data[0][0].max(axis=0)\n",
    "#norm_train_data = train_data / train_data.max(axis=0)\n",
    "#norm_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)  # Pixels\n",
    "#X = np.array([i[0] for i in train_data])  # Pixels\n",
    "#Y = [i[1] for i in train_data]  # Labels\n",
    "#Y = [i[1][0] for i in train_data]  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and validation set for the fitting\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = 0.2, random_state=random_seed)\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "nb_train_samples = len(X_train)\n",
    "nb_validation_samples = len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, strides=3, padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu'))\n",
    "#model.add(Convolution2D(32, 3, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, 3, strides=3, padding='same', activation='relu'))\n",
    "#model.add(Convolution2D(64, 3, 3, padding='same', activation='relu'))\n",
    "#model.add(Convolution2D(64, 3, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(64, 3, strides=3, padding='same', activation='relu'))\n",
    "#model.add(Convolution2D(128, 3, 3, padding='same', activation='relu'))\n",
    "#model.add(Convolution2D(128, 3, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#   model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#   model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#   model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#   model.add(Convolution2D(256, 3, 3, padding='same', activation='relu'))\n",
    "#   model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 50, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 32,865\n",
      "Trainable params: 32,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(np.array(X_train), Y_train, batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(np.array(X_val), Y_val, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 130s 104ms/step - loss: 0.6581 - accuracy: 0.5947 - val_loss: 0.5809 - val_accuracy: 0.6554\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 131s 105ms/step - loss: 0.5904 - accuracy: 0.6894 - val_loss: 0.4654 - val_accuracy: 0.7041\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.5536 - accuracy: 0.7226 - val_loss: 0.6506 - val_accuracy: 0.7301\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 126s 101ms/step - loss: 0.5350 - accuracy: 0.7359 - val_loss: 0.5300 - val_accuracy: 0.7378\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.5173 - accuracy: 0.7482 - val_loss: 0.4596 - val_accuracy: 0.7568\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 127s 102ms/step - loss: 0.5038 - accuracy: 0.7581 - val_loss: 0.6307 - val_accuracy: 0.7685\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 124s 99ms/step - loss: 0.4974 - accuracy: 0.7642 - val_loss: 0.4660 - val_accuracy: 0.7616\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 126s 100ms/step - loss: 0.4935 - accuracy: 0.7712 - val_loss: 0.7452 - val_accuracy: 0.7558\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 128s 103ms/step - loss: 0.4867 - accuracy: 0.7757 - val_loss: 0.3245 - val_accuracy: 0.7667\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 120s 96ms/step - loss: 0.4752 - accuracy: 0.7824 - val_loss: 0.7623 - val_accuracy: 0.7815\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 119s 95ms/step - loss: 0.4800 - accuracy: 0.7785 - val_loss: 0.2960 - val_accuracy: 0.7837\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 122s 98ms/step - loss: 0.4793 - accuracy: 0.7799 - val_loss: 0.4258 - val_accuracy: 0.7502\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 115s 92ms/step - loss: 0.4816 - accuracy: 0.7788 - val_loss: 0.2566 - val_accuracy: 0.7829\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 112s 90ms/step - loss: 0.4738 - accuracy: 0.7844 - val_loss: 0.6600 - val_accuracy: 0.7735\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4749 - accuracy: 0.7831 - val_loss: 0.5333 - val_accuracy: 0.7640\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4787 - accuracy: 0.7813 - val_loss: 0.4066 - val_accuracy: 0.7909\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4865 - accuracy: 0.7782 - val_loss: 0.2879 - val_accuracy: 0.7488\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4879 - accuracy: 0.7788 - val_loss: 0.2758 - val_accuracy: 0.7885\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 0.4940 - accuracy: 0.7779 - val_loss: 0.4549 - val_accuracy: 0.7913\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4886 - accuracy: 0.7759 - val_loss: 0.6271 - val_accuracy: 0.7562\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4968 - accuracy: 0.7723 - val_loss: 0.5404 - val_accuracy: 0.7749\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4926 - accuracy: 0.7776 - val_loss: 0.3437 - val_accuracy: 0.7646\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4929 - accuracy: 0.7757 - val_loss: 1.0389 - val_accuracy: 0.7915\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 112s 89ms/step - loss: 0.4919 - accuracy: 0.7735 - val_loss: 0.8241 - val_accuracy: 0.7717\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4909 - accuracy: 0.7786 - val_loss: 0.8196 - val_accuracy: 0.7341\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4959 - accuracy: 0.7759 - val_loss: 0.3014 - val_accuracy: 0.7857\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4964 - accuracy: 0.7750 - val_loss: 0.3347 - val_accuracy: 0.7933\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4929 - accuracy: 0.7774 - val_loss: 0.3080 - val_accuracy: 0.7845\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4903 - accuracy: 0.7786 - val_loss: 0.3222 - val_accuracy: 0.7845\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 111s 89ms/step - loss: 0.4948 - accuracy: 0.7771 - val_loss: 0.5876 - val_accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "#history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "#                              epochs = epochs, validation_data = (X_val,Y_val),\n",
    "#                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "#                              , callbacks=[learning_rate_reduction])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    verbose = 1,\n",
    "    validation_steps=nb_validation_samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_wieghts.h5')\n",
    "model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [00:41<00:00, 298.95it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = prepare_data(test_images_dogs_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 74s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator = val_datagen.flow(np.array(X_test), batch_size=batch_size)\n",
    "prediction_probabilities = model.predict_generator(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = range(1, len(test_images_dogs_cats) + 1)\n",
    "solution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\n",
    "cols = ['label']\n",
    "\n",
    "for col in cols:\n",
    "    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n",
    "\n",
    "solution.to_csv(\"solution.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
